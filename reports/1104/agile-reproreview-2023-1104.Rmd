---
title: "Reproducibility review of: Detecting Road Damages in Mobile Mapping Point Clouds using Competitive Reconstruction Networks"
author: "Daniel Nüst \\orcid{0000-0002-0024-5046}"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output:
  pdf_document:
    toc: false
    latex_engine: xelatex
papersize: a4
header-includes:
  - |
    % https://tex.stackexchange.com/questions/445563/ieeetran-how-to-include-orcid-in-tex-pdf-with-pdflatex/445583 (works with pdflatex)
    \usepackage{scalerel}
    \usepackage{tikz}
    \usetikzlibrary{svg.path}
    \definecolor{orcidlogocol}{HTML}{A6CE39}
    \tikzset{
      orcidlogo/.pic={
        \fill[orcidlogocol] svg{M256,128c0,70.7-57.3,128-128,128C57.3,256,0,198.7,0,128C0,57.3,57.3,0,128,0C198.7,0,256,57.3,256,128z};
        \fill[white] svg{M86.3,186.2H70.9V79.1h15.4v48.4V186.2z}
                     svg{M108.9,79.1h41.6c39.6,0,57,28.3,57,53.6c0,27.5-21.5,53.6-56.8,53.6h-41.8V79.1z     M124.3,172.4h24.5c34.9,0,42.9-26.5,42.9-39.7c0-21.5-13.7-39.7-43.7-39.7h-23.7V172.4z}
                     svg{M88.7,56.8c0,5.5-4.5,10.1-10.1,10.1c-5.6,0-10.1-4.6-10.1-10.1c0-5.6,4.5-10.1,10.1-10.1C84.2,46.7,88.7,51.3,88.7,56.8z};
      }
    }
    \newcommand\orcid[1]{\href{https://orcid.org/#1}{\raisebox{0.15 em}{\mbox{\scalerel*{
    \begin{tikzpicture}[yscale=-1, transform shape]
    \pic{orcidlogo};
    \end{tikzpicture}
    }{|}}}}}
    \definecolor{agileblue}{RGB}{0,77,155}
urlcolor: agileblue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

```{r logo, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', out.width='0.3\\linewidth', fig.pos='H'}
temp <- tempfile(fileext = ".pdf")
download.file(url = "https://reproducible-agile.github.io/public/images/reproducible-AGILE-logo-square.pdf", destfile = temp)
knitr::include_graphics(temp)
```

This report is part of the reproducibility review at the AGILE conference.
For more information see [https://reproducible-agile.github.io/](https://reproducible-agile.github.io/).
This document is published on OSF at TODO OSF LINK HERE.
To cite the report use

> TODO FULL REPORT CITATION HERE

# Reviewed paper

TODO ADD FULL CITATION

# Summary

\clearpage

# Reproducibility reviewer notes

The submission at hand was already deanonimized when this reproducibility review started and points to a public GitHub repository at <https://github.com/Snagnar/CompetitiveReconstructionNetworks> which is also archived at <https://doi.org/10.5281/zenodo.7750418> (original version used for first reproduction: <https://doi.org/10.5281/zenodo.7682032>, changes: <https://github.com/Snagnar/CompetitiveReconstructionNetworks/compare/v1.0.0...v1.0.1>).

```{bash, eval=FALSE}
git clone https://github.com/Snagnar/CompetitiveReconstructionNetworks.git
```

The repositories contain a license and a README and seem pretty well set up.
I continue following the instructions in the README to set up the computational environment with pinned dependencies, resulting in the following environment on my machine:

```{bash, size="tiny", eval=FALSE}
$ pip freeze
aiohttp==3.8.4
aiosignal==1.3.1
appdirs==1.4.4
async-timeout==4.0.2
attrs==22.2.0
certifi==2022.12.7
charset-normalizer==3.1.0
click==8.1.3
docker-pycreds==0.4.0
frozenlist==1.3.3
fsspec==2023.3.0
gitdb==4.0.10
GitPython==3.1.31
idna==3.4
imageio==2.25.1
joblib==1.2.0
lightning-utilities==0.8.0
multidict==6.0.4
numpy==1.24.2
nvidia-cublas-cu11==11.10.3.66
nvidia-cuda-nvrtc-cu11==11.7.99
nvidia-cuda-runtime-cu11==11.7.99
nvidia-cudnn-cu11==8.5.0.96
packaging==23.0
pathtools==0.1.2
Pillow==9.4.0
protobuf==4.22.1
psutil==5.9.4
pytorch-lightning==1.9.2
PyYAML==6.0
requests==2.28.2
scikit-learn==1.2.1
scipy==1.10.1
sentry-sdk==1.16.0
setproctitle==1.3.2
six==1.16.0
smmap==5.0.0
threadpoolctl==3.1.0
torch==1.13.1
torchaudio==0.13.1+rocm5.2
torchmetrics==0.11.4
torchvision==0.14.1
tqdm==4.64.1
typing_extensions==4.5.0
urllib3==1.26.15
wandb==0.13.10
yarl==1.8.2
```

The information regarding computing times is very helpful, as I think I am unlikely to run this with GPU-features on my machine, but it is worth a try... with <https://pytorch.org/> I run the following commands.

```{bash, size="tiny", eval=FALSE}
pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/rocm5.2

amdgpu-install
rocminfo
```

## Data download

```{bash, size="tiny", eval=FALSE}
mkdir datasets
cd datasets
mkdir mvtec
cd mvtec

wget https://www.mydrive.ch/shares/38536/3830184030e49fe74747669442f0f282/download/420938113-1629952094/mvtec_anomaly_detection.tar.xz
tar -xvf mvtec_anomaly_detection.tar.xz
```

```{bash, size="tiny", eval=FALSE}
cd datasets # same as above
wget -O panorama.zip https://zenodo.org/record/7681876/files/panorama.zip?download=1
wget -O road_images.zip https://zenodo.org/record/7681876/files/road_images.zip?download=1
```

After adjusting directory names based on the input to the `--dataset-path` argument in the README, I have the followign file tree:

```{bash, size="tiny", eval=FALSE}
$ tree --du -h -L 2 datasets/
[5.2G]  datasets/
├── [4.9G]  mvtec
│   ├── [4.0K]  bottle
│   ├── [4.0K]  cable
│   ├── [4.0K]  capsule
│   ├── [4.0K]  carpet
│   ├── [4.0K]  grid
│   ├── [4.0K]  hazelnut
│   ├── [4.0K]  leather
│   ├── [ 20K]  license.txt
│   ├── [4.0K]  metal_nut
│   ├── [4.9G]  mvtec_anomaly_detection.tar.xz
│   ├── [4.0K]  pill
│   ├── [ 881]  readme.txt
│   ├── [4.0K]  screw
│   ├── [4.0K]  tile
│   ├── [4.0K]  toothbrush
│   ├── [4.0K]  transistor
│   ├── [4.0K]  wood
│   └── [4.0K]  zipper
├── [ 72K]  panorama
│   ├── [ 56K]  bad_ones
│   └── [ 12K]  good_ones
├── [229M]  panorama.zip
├── [ 12K]  roadimages
│   ├── [4.0K]  bad_ones
│   └── [4.0K]  good_ones
└── [ 43M]  road_images.zip
```

## Run experiments

After failing to run experiments, the authors provided a reduced version of their pipeline, a "demo mode".
(The source of this document still contains the full attempted steps.)

<!--

With just a fraction of the suggested steps (`200` instead of `20000`), forcing CPU (because log output in the first tries shows GPU does not work), and setting competitive unit number as suggested in the README.
The log also suggests to increase `num_workers` but that parameter does not seem to be handled in the script.

```{bash, size="tiny", eval=FALSE}
python train.py --mode train --training-steps 200 --model crn --dataset MVTec --auto-set-name --dataset-path=datasets/mvtec/cable --num-competitive-units 2 --cpu
```

PROBLEM: CPUs max out, RAM usage goes up to 38 GB, but no progress after 10 minutes on the progress bar.

```{bash, size="tiny", eval=FALSE}
2023-03-15 20:13:41 - INFO [dataset.py : __init__() : l. 120]: caching images...
2023-03-15 20:13:52 - INFO [dataset.py : __init__() : l. 120]: caching images...
2023-03-15 20:13:58 - INFO [train.py : main() : l. 74]: Dataset created!
2023-03-15 20:13:58 - INFO [train.py : main() : l. 89]: creating trainer....
/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.
  rank_zero_deprecation(
/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:751: UserWarning: You passed `Trainer(accelerator='cpu', precision=16)` but native AMP is not supported on CPU. Using `precision='bf16'` instead.
  rank_zero_warn(
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
  warning_cache.warn(
2023-03-15 20:13:58 - INFO [train.py : main() : l. 108]: Trainer created!
2023-03-15 20:13:58 - INFO [train.py : main() : l. 113]: training model....
2023-03-15 20:13:58 - INFO [train.py : main() : l. 115]: Training new model...
2023-03-15 20:13:58 - INFO [crn.py : __init__() : l. 57]: using network depth 7
/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/core/module.py:416: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`
  rank_zero_warn(
2023-03-15 20:13:59 - INFO [train.py : main() : l. 121]: Model created!
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/12
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/12
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/12
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/12
Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/12
Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/12
Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/12
Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/12
Initializing distributed: GLOBAL_RANK: 8, MEMBER: 9/12
Initializing distributed: GLOBAL_RANK: 9, MEMBER: 10/12
Initializing distributed: GLOBAL_RANK: 10, MEMBER: 11/12
Initializing distributed: GLOBAL_RANK: 11, MEMBER: 12/12
----------------------------------------------------------------------------------------------------
distributed_backend=gloo
All distributed processes registered. Starting with 12 processes
----------------------------------------------------------------------------------------------------


  | Name                         | Type       | Params
------------------------------------------------------------
0 | adversarial_loss_function    | L1Loss     | 0     
1 | reconstruction_loss_function | L1Loss     | 0     
2 | competitive_units            | ModuleList | 60.5 M
------------------------------------------------------------
60.5 M    Trainable params
0         Non-trainable params
60.5 M    Total params
241.943   Total estimated model params size (MB)
/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:217: UserWarning: strategy=ddp_spawn and num_workers=0 may result in data loading bottlenecks. Consider setting num_workers>0 and persistent_workers=True
  rank_zero_warn(
/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1609: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=2). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
Epoch 0:   0%|                                                                                                                                         | 0/2 [00:00<?, ?it/s^C/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  rank_zero_warn("Detected KeyboardInterrupt, attempting graceful shutdown...")
```

-->

```{bash, size="tiny", eval=FALSE}
$ python train.py --mode train --dataset RoadImages --dataset-path datasets/roadimages --model crn --demo --num-workers 4 --cpu --seed 41020
Global seed set to 41020
WARNING:root:DEMO MODE ACTIVATED! training with batch size 2 for 100 training steps and image size 32x32. Networks have a maximum depth of 3 and only 3 competitive units are used.
in partition train files: 95
True 95
caching...
in partition test files: 509
False 509
caching...
INFO:root:Dataset created!
2023-04-04 12:20:06 - INFO [train.py : main() : l. 88]: Dataset created!
INFO:root:creating trainer....
2023-04-04 12:20:06 - INFO [train.py : main() : l. 103]: creating trainer....
/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:585: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.
  rank_zero_deprecation(
/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:744: UserWarning: You passed `Trainer(accelerator='cpu', precision=16)` but native AMP is not supported on CPU. Using `precision='bf16'` instead.
  rank_zero_warn(
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
  warning_cache.warn(
INFO:root:Trainer created!
2023-04-04 12:20:06 - INFO [train.py : main() : l. 122]: Trainer created!
INFO:root:training model....
2023-04-04 12:20:06 - INFO [train.py : main() : l. 127]: training model....
INFO:root:Training new model...
2023-04-04 12:20:06 - INFO [train.py : main() : l. 129]: Training new model...
INFO:root:using network depth 2
2023-04-04 12:20:06 - INFO [crn.py : __init__() : l. 57]: using network depth 2
/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/core/module.py:416: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`
  rank_zero_warn(
INFO:root:Model created!
2023-04-04 12:20:07 - INFO [train.py : main() : l. 135]: Model created!
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/3
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/3
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/3
----------------------------------------------------------------------------------------------------
distributed_backend=gloo
All distributed processes registered. Starting with 3 processes
----------------------------------------------------------------------------------------------------


  | Name                         | Type       | Params
------------------------------------------------------------
0 | adversarial_loss_function    | L1Loss     | 0     
1 | reconstruction_loss_function | L1Loss     | 0     
2 | competitive_units            | ModuleList | 37.2 M
------------------------------------------------------------
37.2 M    Trainable params
0         Non-trainable params
37.2 M    Total params
148.955   Total estimated model params size (MB)
Epoch 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 34/34 [02:46<00:00,  4.88s/it, v_num=3]Exception computing roc:  Only one class present in y_true. ROC AUC score is not defined in that case.█████████████████████████████████████████████████████████████████| 17/17 [00:16<00:00,  1.06it/s]
Exception computing roc:  Only one class present in y_true. ROC AUC score is not defined in that case.
terminate called after throwing an instance of 'gloo::EnforceNotMet'
  what():  [enforce fail at ../third_party/gloo/gloo/transport/tcp/pair.cc:510] op.preamble.length <= op.nbytes. 8 vs 4
Traceback (most recent call last):
  File "/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/train.py", line 215, in <module>
    main(args)
  File "/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/train.py", line 136, in main
    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=[val_loader])
  File "/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
    call._call_and_handle_interrupt(
  File "/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 36, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py", line 113, in launch
    mp.start_processes(
  File "/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 198, in start_processes
    while not context.join():
  File "/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 140, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 1 terminated with signal SIGABRT
```

**The above code fails.**
It is also noteworthy that the logging warning and the actual used values for parameters (batch size, training steps) mismatch.

## Figure 7

I give one of the commands to recreate the figure, with number of competetive units at `12`, a try with only 50 steps:

```{bash, size="tiny", eval=FALSE}
python train.py --mode train --training-steps 50 --model crn --dataset MVTec --dataset-path=datasets/mvtec/cable --seed 41020 --num-competitive-units 12

Global seed set to 41020
2023-04-04 13:13:23 - INFO [dataset.py : __init__() : l. 120]: caching images...
2023-04-04 13:13:32 - INFO [dataset.py : __init__() : l. 120]: caching images...
2023-04-04 13:13:38 - INFO [train.py : main() : l. 88]: Dataset created!
2023-04-04 13:13:38 - INFO [train.py : main() : l. 103]: creating trainer....
/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:585: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.
  rank_zero_deprecation(
/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:744: UserWarning: You passed `Trainer(accelerator='cpu', precision=16)` but native AMP is not supported on CPU. Using `precision='bf16'` instead.
  rank_zero_warn(
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
  warning_cache.warn(
2023-04-04 13:13:38 - INFO [train.py : main() : l. 122]: Trainer created!
2023-04-04 13:13:38 - INFO [train.py : main() : l. 127]: training model....
2023-04-04 13:13:38 - INFO [train.py : main() : l. 129]: Training new model...
2023-04-04 13:13:38 - INFO [crn.py : __init__() : l. 57]: using network depth 7
/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/core/module.py:416: UserWarning: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`
  rank_zero_warn(
2023-04-04 13:13:41 - INFO [train.py : main() : l. 135]: Model created!
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2
----------------------------------------------------------------------------------------------------
distributed_backend=gloo
All distributed processes registered. Starting with 2 processes
----------------------------------------------------------------------------------------------------


  | Name                         | Type       | Params
------------------------------------------------------------
0 | adversarial_loss_function    | L1Loss     | 0     
1 | reconstruction_loss_function | L1Loss     | 0     
2 | competitive_units            | ModuleList | 362 M 
------------------------------------------------------------
362 M     Trainable params
0         Non-trainable params
362 M     Total params
1,451.655 Total estimated model params size (MB)
/home/daniel/git/reproducible-agile/reviews-2023/reports/1104/CompetitiveReconstructionNetworks/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:217: UserWarning: strategy=ddp_spawn and num_workers=0 may result in data loading bottlenecks. Consider setting num_workers>0 and persistent_workers=True
  rank_zero_warn(
Epoch 7:  33%|██████████████████████████████████████▎                                                                            | 1/3 [37:32<1:15:05, 2252.64s/it, v_num=5, metrics/max_roc_auc=0.570]
Epoch 7:  67%|████████████████████████████████████████████████████                          | 2/3 [1:03:36<31:48, 1908.39s/it, v_num=5, metrics/max_roc_auc=0.570]Epoch 12:  33%|█████████████████████████▋                                                   | 1/3 [33:01<1:06:03, 1981.94s/it, v_num=5, metrics/max_roc_auc=0.570]`Trainer.fit` stopped: `max_steps=50` reached.                                                                                                                    
Epoch 12:  33%|█████████████████████████▋                                                   | 1/3 [33:01<1:06:03, 1981.95s/it, v_num=5, metrics/max_roc_auc=0.570]
```

This commands completes after running over night.
The README lacks documentation what should be the result.
I do find a directory `ligning_logs/version_5` that has some files in it (other `version_x` directories next to it are empty, these could be previous faulty runs?):

```{bash, size="tiny", eval=FALSE}
$ tree lightning_logs/
lightning_logs/
├── version_0
├── version_1
├── version_2
├── version_3
├── version_4
└── version_5
    ├── hparams.yaml
    └── metrics.csv
```

The contents of the two files are as follows.

`hparams.yaml`

```{r engine='bash', size="tiny", comment=''}
cat CompetitiveReconstructionNetworks/lightning_logs/version_5/hparams.yaml
```

`metrics.csv`

```{r engine='bash', size="tiny", comment=''}
cat CompetitiveReconstructionNetworks/lightning_logs/version_5/metrics.csv
```

## Evaluation

```{bash, size="tiny", eval=FALSE}
python train.py --mode train --dataset Panorama --dataset-path datasets/panorama --model crn
```

<!--
To evaluate CRN on the annotated road images, use the following command:
```bash
python train.py --mode train --dataset RoadImages --dataset-path datasets/roadimages --model crn
```

## Run the inference

To run inference, you first need to train a model and store checkpoints using the `--checkpoint-path` flag, e.g. for road images:
```bash
python train.py --mode train --dataset RoadImages --dataset-path datasets/roadimages --model crn --checkpoint-path model_checkpoints
```
This stores the best CRN state in `model_checkpoints/`.

To calculate anomaly scores for one whole datasets as well as anomaly pictures, use the following command:
```bash
python train.py --mode inference --dataset Panorama --dataset-path datasets/panorama_converted --model crn --model-input "model_checkpoints/last.ckpt" --image-output-path inference_images/
```
For `--model-input` make sure to give the correct path to the last model checkpoint.

To make inference for different datasets, (RoadImages, MVTec or Panorama) adjust the `--dataset` and `--dataset-path` parameters accordingly.

After inference, you can look at the pictures generated in the `diff` directory to make a qualitative evaluation of the results.
-->

## Run the hyperparameter tuning

I did not attempt this because of the required account for the _Weights & Biases_ platform, see <https://wandb.ai/>.
Free accounts are available, but I do not have one.

## Outputs/visualisations

TODO: Table 1 (or at least one command in a reduced fashion)

TODO: Table 2 (or at least one command in a reduced fashion)

TODO: Table 3 (or at least one command in a reduced fashion)

TODO: Figure 6 (or at least one command in a reduced fashion)

TODO: Figure 7 (or at least one command in a reduced fashion)

<!--
Overall, the workflow is well documented and readily reproducible, if suitable storage and computational resources are available for the actual dataset.
Good job!
-->

## Recommendations

The authors made some considerable updates after sharing a first draft or this report, see [comparison on GitHub](https://github.com/Snagnar/CompetitiveReconstructionNetworks/compare/v1.0.0...v1.0.1) (from tag 1.0.0 to 1.0.1), which leads to some ~~fixed recommendations~~.

- ~~Pin the computing environment so that the `requirements.txt` contains the actual versions you use(d)~~
- ~~You mention the used hardware - please complement this information with the run times you experienced for training, inference, etc. so that others can adjust their expectations (or configurations)~~
- ~~In your README, please add the to be expected data download sizes~~
- ~~It seems like you provide the direct download link for the MVTec AD dataset that is accessible after providing information on  <https://www.mvtec.com/company/research/datasets/mvtec-ad>; I suggest to mention the original URL in the README, just in case the direct download link changes~~
- For reproducibility evaluation (and possibly also demonstration), it would be great if you could provide a couple of ~~example commands and~~ corresponding outputs ~~that run on a small subset of the data with CPU only, so that I can run the whole workflow in 10 Minutes~~ and know if my outputs match yours; extra points for making the repo [Binder-ready](https://elifesciences.org/labs/8653a61d/introducing-binder-2-0-share-your-interactive-research-environment) with such a test dataset
- ~~Use only paths relative to a project directory that you specific clearly: when I follow the instructions to the letter, I will extract the MVTec dataset to `mvtec/` and only afterwards create `datasets/` next to it, but the first training command expects a directory `datasets/mvtec/..` to exist~~
- ~~I see in the code some option to configure a seed - do that!~~

```{r, echo=FALSE, eval=FALSE, results='hide'}
# create ZIP of reproduction files and upload to OSF
library("zip")
library("here")

zipfile <- here::here("PATH/agile-reproreview-YEAR-NUMBER.zip")
file.remove(zipfile)
zip::zipr(zipfile,
          here::here("2020-018/files to add to the zip, if any"))

library("osfr") # See docs at https://docs.ropensci.org/osfr/
# OSF_PAT is in .Renviron in parent directory
# We cannot use osfr to create a new component (with osfr::osf_create_component(x = osfr::osf_retrieve_node("6k5fh"), ...) because that will set the storage location to outside Europe.

# retrieve project
project <- osfr::osf_retrieve_node("OSF ID")

# upload files
osfr::osf_upload(x = project,
                 conflicts = "overwrite",
                 path = c(list.files(here::here("PATH"),
                                     pattern = "agile-reproreview-.*(pdf$|Rmd$|zip$)",
                                     full.names = TRUE),
                          "COPYRIGHT"
                          )
                 )
```